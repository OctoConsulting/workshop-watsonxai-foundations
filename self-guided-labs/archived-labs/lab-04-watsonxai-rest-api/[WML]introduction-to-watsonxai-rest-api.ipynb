{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814c2eae",
   "metadata": {},
   "source": [
    "# Accesing Watsonx.ai via REST API\n",
    "\n",
    "In this lab, we will take a comprehensive look at making HTTP requests to access [Watsonx.ai's REST API](https://workbench.res.ibm.com/docs/api-reference) and learn how to use the functionality.  This lab explore only a few of the many REST endpoints available so explore the REST API documentation to view the full list of capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21edff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from ibm_cloud_sdk_core import IAMTokenManager\n",
    "import json\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5d00e",
   "metadata": {},
   "source": [
    "## HTTP request headers\n",
    "Headers contain parameter values that represent the metadata associated with an API requests and response. In the following example, the Authorization header provides the server with credentials to validate your access.  Watsonx.ai uses a \"Bearer\" access token wich is used to pass our Watsonx.ai authentication key.  The 'Content-type' header in the request is added to tell the server or the browser which is serving the resource to the end user about the media type of the request. In this case, type of expected data as 'application/json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12703f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\", None)\n",
    "ibm_cloud_url= os.getenv(\"IBM_CLOUD_URL\", None)\n",
    "project_id= os.getenv(\"PROJECT_ID\", None)\n",
    "if api_key is None or ibm_cloud_url is None or project_id is None:\n",
    "    print(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\n",
    "else:\n",
    "    access_token = IAMTokenManager(\n",
    "        apikey = api_key,\n",
    "        url = \"https://iam.cloud.ibm.com/identity/token\").get_token()       \n",
    "    headers = {\n",
    "            \"Authorization\": \"Bearer \" + access_token,\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ed0a8",
   "metadata": {},
   "source": [
    "## POST vs GET\n",
    "HTTP requests come in two flavors: GET and POST.  When using GET, data parameters are included in the URL and visible to everyone. However, when using POST, data is not displayed in the URL but is instead passed in the HTTP message body. \n",
    "\n",
    "GET requests are intended to retrieve data from a server and do not modify the server’s state. On the other hand, POST requests are used to send data to the server for processing and may modify the server’s state.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3957d6d2",
   "metadata": {},
   "source": [
    "## POST requests with 'Generate' endpoint\n",
    "\n",
    "The generate endpoint \"https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text\" provides an interface for sending prompts to any model supported by Watsonx.ai. Given a text prompt as inputs, and required parameters, the selected model will attempt to complete the provide input and return \"generated_text\".\n",
    "\n",
    "Request body needs to include:\n",
    "- Model id (string): the id of the model\n",
    "- Input (string): prompt to generate completion\n",
    "- Parameters for the model (key-value pairs)\n",
    "- your watsonx project ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75eb0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "body={\n",
    "  \"model_id\": \"google/flan-ul2\",\n",
    "  \"input\": \"Write a short blog post for an advanced cloud service for large language models: This service is\",\n",
    "  \"parameters\": {\n",
    "    \"temperature\": 0,\n",
    "    \"max_new_tokens\": 50,\n",
    "    \"min_new_tokens\": 25\n",
    "  },\n",
    "  \"project_id\":project_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f01a3f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Response:  {'errors': [{'code': 'token_quota_reached', 'message': 'Request of 1 token(s) from quota was rejected'}], 'trace': '9c52c1860914888ad12479a674468237', 'status_code': 403}\n"
     ]
    }
   ],
   "source": [
    "generation_endpoint = ibm_cloud_url + \"/ml/v1-beta/generation/text?version=2023-07-07\"\n",
    "response=requests.post(url=generation_endpoint, headers=headers, json=body )\n",
    "print(\"JSON Response: \",response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6b9a0",
   "metadata": {},
   "source": [
    "## Using GET requests to retrieve data\n",
    "The GET method is used to retrieve information from Watsonx.ai using a given URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4fc3f",
   "metadata": {},
   "source": [
    "### GET /models\n",
    "Get the list of all models supported by Watsonx.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be28271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 models supported the Watsonx.ai\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model_id': 'bigscience/mt0-xxl',\n",
       "  'label': 'mt0-xxl-13b',\n",
       "  'provider': 'BigScience',\n",
       "  'source': 'Hugging Face',\n",
       "  'short_description': 'An instruction-tuned iteration on mT5.',\n",
       "  'long_description': 'mt0-xxl (13B) is an instruction-tuned iteration on mT5. Like BLOOMZ, it was fine-tuned on a cross-lingual task mixture dataset (xP3) using multitask prompted finetuning (MTF).',\n",
       "  'task_ids': ['question_answering',\n",
       "   'summarization',\n",
       "   'classification',\n",
       "   'generation'],\n",
       "  'tasks': [{'id': 'question_answering', 'ratings': {'quality': 3}},\n",
       "   {'id': 'summarization', 'ratings': {'quality': 3}},\n",
       "   {'id': 'classification', 'ratings': {'quality': 3}},\n",
       "   {'id': 'extraction', 'ratings': {'quality': 2}}],\n",
       "  'limits': {'lite': {'call_time': '5m0s',\n",
       "    'max_output_tokens': 700,\n",
       "    'max_input_tokens': 0},\n",
       "   'v2-professional': {'call_time': '5m0s',\n",
       "    'max_output_tokens': 700,\n",
       "    'max_input_tokens': 0},\n",
       "   'v2-standard': {'call_time': '5m0s',\n",
       "    'max_output_tokens': 700,\n",
       "    'max_input_tokens': 0}},\n",
       "  'min_shot_size': 0,\n",
       "  'tier': 'class_2',\n",
       "  'number_params': '13b'},\n",
       " {'model_id': 'eleutherai/gpt-neox-20b',\n",
       "  'label': 'gpt-neox-20b',\n",
       "  'provider': 'EleutherAI',\n",
       "  'source': 'Hugging Face',\n",
       "  'short_description': 'A 20 billion parameter autoregressive language model trained on the Pile.',\n",
       "  'long_description': 'gpt-neox-20b (20B) is a 20 billion parameter autoregressive language model trained on the Pile.',\n",
       "  'task_ids': ['summarization', 'classification', 'generation'],\n",
       "  'tasks': [{'id': 'question_answering', 'ratings': {'quality': 2}},\n",
       "   {'id': 'summarization', 'ratings': {'quality': 3}},\n",
       "   {'id': 'classification', 'ratings': {'quality': 3}},\n",
       "   {'id': 'extraction', 'ratings': {'quality': 2}}],\n",
       "  'limits': {'lite': {'call_time': '5m0s',\n",
       "    'max_output_tokens': 700,\n",
       "    'max_input_tokens': 0},\n",
       "   'v2-professional': {'call_time': '5m0s',\n",
       "    'max_output_tokens': 700,\n",
       "    'max_input_tokens': 0},\n",
       "   'v2-standard': {'call_time': '5m0s',\n",
       "    'max_output_tokens': 700,\n",
       "    'max_input_tokens': 0}},\n",
       "  'min_shot_size': 1,\n",
       "  'tier': 'class_3',\n",
       "  'number_params': '20b'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_endpoint = ibm_cloud_url + \"/ml/v1-beta/foundation_model_specs?version=2023-07-07\"\n",
    "response = requests.get(url = model_endpoint, headers=headers)\n",
    "models = response.json()['resources']\n",
    "\n",
    "print(f\"{len(models)} models supported the Watsonx.ai\")\n",
    "\n",
    "# Print the first two models\n",
    "models[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e4f10",
   "metadata": {},
   "source": [
    "### Lab Complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
