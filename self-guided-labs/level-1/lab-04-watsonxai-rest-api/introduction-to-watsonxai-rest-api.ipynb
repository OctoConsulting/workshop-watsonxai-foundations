{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814c2eae",
   "metadata": {},
   "source": [
    "# Accesing Watsonx.ai via REST API\n",
    "\n",
    "In this lab, we will take a comprehensive look at making HTTP requests to access [Watsonx.ai's REST API](https://workbench.res.ibm.com/docs/api-reference) and learn how to use the functionality.  This lab explore only a few of the many REST endpoints available so explore the REST API documentation to view the full list of capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21edff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5d00e",
   "metadata": {},
   "source": [
    "## HTTP request headers\n",
    "Headers contain parameter values that represent the metadata associated with an API requests and response. In the following example, the Authorization header provides the server with credentials to validate your access.  Watsonx.ai uses a \"Bearer\" access token wich is used to pass our Watsonx.ai authentication key.  The 'Content-type' header in the request is added to tell the server or the browser which is serving the resource to the end user about the media type of the request. In this case, type of expected data as 'application/json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12703f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_endpoint = os.getenv(\"GENAI_API\", None)\n",
    "if api_key is None or api_endpoint is None:\n",
    "    print(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\n",
    "else:\n",
    "    headers={\"Authorization\": f\"Bearer {api_key}\",\n",
    "             \"Content-Type\":\"application/json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ed0a8",
   "metadata": {},
   "source": [
    "## POST vs GET\n",
    "HTTP requests come in two flavors: GET and POST.  When using GET, data parameters are included in the URL and visible to everyone. However, when using POST, data is not displayed in the URL but is instead passed in the HTTP message body. \n",
    "\n",
    "GET requests are intended to retrieve data from a server and do not modify the server’s state. On the other hand, POST requests are used to send data to the server for processing and may modify the server’s state.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3957d6d2",
   "metadata": {},
   "source": [
    "## POST requests with 'Generate' endpoint\n",
    "\n",
    "The generate endpoint \"https://workbench-api.res.ibm.com/v1/generate\" provides an interface for sending prompts to any model supported by Watsonx.ai. Given a text prompt as inputs, and required parameters, the selected model will attempt to complete the provide input and return \"generated_text\".\n",
    "\n",
    "Request body needs to include:\n",
    "- Model id (string): the id of the model\n",
    "- Inputs (array of strings): prompts to generate completions\n",
    "- Parameters for the model (key-value pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75eb0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "body={\n",
    "  \"model_id\": \"google/flan-ul2\",\n",
    "  \"inputs\": [\"Write a short blog post for an advanced cloud service for large language models: This service is\"],\n",
    "  \"parameters\": {\n",
    "    \"temperature\": 0,\n",
    "    \"max_new_tokens\": 50,\n",
    "    \"min_new_tokens\": 25\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01a3f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Response:  {'model_id': 'google/flan-ul2', 'created_at': '2023-06-30T14:42:20.761Z', 'results': [{'generated_text': 'a new cloud service for large language models. It is a scalable, high-performance, and secure service for training and deploying language models.', 'generated_token_count': 33, 'input_token_count': 20, 'stop_reason': 'EOS_TOKEN'}]}\n"
     ]
    }
   ],
   "source": [
    "url=f\"{api_endpoint}generate\" \n",
    "response=requests.post(url=url, headers=headers, json=body )\n",
    "print(\"JSON Response: \",response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47fc23da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results: [\n",
      "  {\n",
      "    \"generated_text\": \"a new cloud service for large language models. It is a scalable, high-performance, and secure service for training and deploying language models.\",\n",
      "    \"generated_token_count\": 33,\n",
      "    \"input_token_count\": 20,\n",
      "    \"stop_reason\": \"EOS_TOKEN\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model results: {json.dumps(response.json()['results'], indent = 2)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6b9a0",
   "metadata": {},
   "source": [
    "## Using GET requests to retrieve data\n",
    "The GET method is used to retrieve information from Watsonx.ai using a given URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4fc3f",
   "metadata": {},
   "source": [
    "### GET /models\n",
    "Get the [list of all models](https://workbench.res.ibm.com/docs/api-reference#list-models) supported by Watsonx.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be28271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 models supported the Watsonx.ai\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'salesforce/codegen-16b-mono',\n",
       "  'name': 'codegen-16b-mono (16B)',\n",
       "  'size': '16B',\n",
       "  'source_model_id': None,\n",
       "  'token_limit': 2048},\n",
       " {'id': 'prakharz/dial-flant5-xl',\n",
       "  'name': 'dial-flant5-xl (3B)',\n",
       "  'size': '3B',\n",
       "  'source_model_id': None,\n",
       "  'token_limit': 4096}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WATSONX_AI_BASE_URL = \"https://workbench-api.res.ibm.com/v1\"\n",
    "\n",
    "url = WATSONX_AI_BASE_URL + \"/models\"\n",
    "response = requests.get(url = url,headers=headers)\n",
    "models = response.json()[\"results\"]\n",
    "\n",
    "print(f\"{len(models)} models supported the Watsonx.ai\")\n",
    "\n",
    "# Print the first two models\n",
    "models[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188484e7",
   "metadata": {},
   "source": [
    "### GET /models/{id}\n",
    "Retrieve [details on a specific model](https://workbench.res.ibm.com/docs/api-reference#list-models) supported by Watsonx.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c91d069d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial model id: salesforce/codegen-16b-mono\n",
      "escaped model id: salesforce%2Fcodegen-16b-mono\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results': {'id': 'salesforce/codegen-16b-mono',\n",
       "  'name': 'codegen-16b-mono (16B)',\n",
       "  'size': '16B',\n",
       "  'disabled': False,\n",
       "  'preferred': True,\n",
       "  'description': 'codegen-16b-mono (16B) is an autoregressive language model for program synthesis trained sequentially on the Pile, BigQuery and BigPython. codegen-mono (16B) is trained with a 16 billion parameter checkpoint.\\n\\n- Repository: [salesforce/CodeGen](https://github.com/salesforce/CodeGen)\\n- Paper: [A Conversational Paradigm for Program Synthesis](https://arxiv.org/abs/2203.13474)\\n- More Information: [from Huggingface](https://huggingface.co/docs/transformers/model_doc/codegen)\\n- License: [BSD 3-Clause](https://github.com/salesforce/CodeGen/blob/main/LICENSE.txt)\\n- Intended Use: \\n    - Extracting features from given natural language and programming language texts, and calculating the likelihood. \\n    - Programming synthesis-generating executable code given English prompts, where the prompts should be in the form of a comment string. \\n    - Completing partially-generated code.',\n",
       "  'tags': ['preview'],\n",
       "  'source_model_id': None,\n",
       "  'token_limit': 2048,\n",
       "  'tasks': [],\n",
       "  'modelFamily': {'id': 5,\n",
       "   'name': 'CodeGen-Mono',\n",
       "   'short_description': 'Code generation for multiple programming languages',\n",
       "   'description': None},\n",
       "  'schema_generate': {'id': 72,\n",
       "   'value': {'type': 'object',\n",
       "    'anyOf': [{'required': ['model_id']}, {'required': ['prompt_id']}],\n",
       "    'required': ['inputs'],\n",
       "    'properties': {'inputs': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'title': 'Input strings',\n",
       "      'examples': ['[\"How are you\"]'],\n",
       "      'maxItems': 5,\n",
       "      'minItems': 1,\n",
       "      'description': 'Array of inputs'},\n",
       "     'model_id': {'type': 'string',\n",
       "      'title': 'Model ID',\n",
       "      'description': 'Model identifier'},\n",
       "     'template': {'type': 'object',\n",
       "      'anyOf': [{'required': ['id']}, {'required': ['value']}],\n",
       "      'nullable': True,\n",
       "      'required': ['data'],\n",
       "      'properties': {'id': {'type': 'string', 'nullable': False},\n",
       "       'data': {'type': 'object',\n",
       "        'nullable': False,\n",
       "        'properties': {'example_file_ids': {'type': 'array',\n",
       "          'items': {'type': 'string'},\n",
       "          'maxItems': 5,\n",
       "          'minItems': 0}},\n",
       "        'additionalProperties': True},\n",
       "       'value': {'type': 'string', 'nullable': False}},\n",
       "      'additionalProperties': False},\n",
       "     'prompt_id': {'type': 'string',\n",
       "      'title': 'Saved prompt Id',\n",
       "      'minLength': 1},\n",
       "     'parameters': {'type': 'object',\n",
       "      'nullable': True,\n",
       "      'properties': {'top_k': {'type': 'integer',\n",
       "        'title': 'Top K',\n",
       "        'default': 50,\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'nullable': True,\n",
       "        'description': 'Set the number of highest probability vocabulary tokens to keep for top-k-filtering. Lower values make it less likely the model will go off topic.'},\n",
       "       'top_p': {'type': 'number',\n",
       "        'title': 'Top P (nucleus sampling)',\n",
       "        'default': 1,\n",
       "        'maximum': 1,\n",
       "        'minimum': 0,\n",
       "        'nullable': True,\n",
       "        'multipleOf': 0.01,\n",
       "        'description': 'If < 1.0, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are used.'},\n",
       "       'stream': {'type': 'boolean',\n",
       "        'title': 'Stream',\n",
       "        'default': False,\n",
       "        'nullable': True,\n",
       "        'description': 'Enables to stream partial progress as server-sent events.'},\n",
       "       'beam_width': {'type': 'integer',\n",
       "        'title': 'Beam width',\n",
       "        'default': 1,\n",
       "        'maximum': 1,\n",
       "        'minimum': 0,\n",
       "        'nullable': True,\n",
       "        'description': 'Multiple output sequences of tokens are generated, using your decoding selection, and then the output sequence with the highest overall probability is returned. When beam search is enabled, there will be a performance penalty, and `Stop sequences` will not be available.'},\n",
       "       'time_limit': {'type': 'integer',\n",
       "        'title': 'Time limit',\n",
       "        'nullable': True,\n",
       "        'description': 'Time limit in milliseconds - if not completed within this time, generation will stop. The text generated so far will be returned along with the `TIME_LIMIT` stop reason.'},\n",
       "       'moderations': {'type': 'object',\n",
       "        'nullable': False,\n",
       "        'properties': {'hap': {'anyOf': [{'type': 'boolean'},\n",
       "           {'type': 'object',\n",
       "            'properties': {'input': {'type': 'boolean'},\n",
       "             'output': {'type': 'boolean'},\n",
       "             'threshold': {'type': 'number',\n",
       "              'default': 0.75,\n",
       "              'exclusiveMaximum': 1,\n",
       "              'exclusiveMinimum': 0},\n",
       "             'send_tokens': {'type': 'boolean', 'default': False}}}],\n",
       "          'default': False}}},\n",
       "       'random_seed': {'type': 'integer',\n",
       "        'title': 'Random seed',\n",
       "        'maximum': 4294967295,\n",
       "        'minimum': 1,\n",
       "        'nullable': True,\n",
       "        'description': 'Controls the random sampling of the generated tokens when sampling is enabled. Setting the random seed to a the same number for each generation ensures experimental repeatability.'},\n",
       "       'temperature': {'type': 'number',\n",
       "        'title': 'Temperature',\n",
       "        'default': 0.7,\n",
       "        'maximum': 2,\n",
       "        'minimum': 0,\n",
       "        'nullable': True,\n",
       "        'multipleOf': 0.01,\n",
       "        'description': 'Control the creativity of generated text. Higher values will lead to more randomly generated outputs.'},\n",
       "       'length_penalty': {'type': 'object',\n",
       "        'title': 'Length penalty',\n",
       "        'nullable': True,\n",
       "        'properties': {'start_index': {'type': 'integer',\n",
       "          'title': 'Start index',\n",
       "          'minimum': 1,\n",
       "          'nullable': True,\n",
       "          'description': 'A number of generated tokens after which this should take effect.'},\n",
       "         'decay_factor': {'type': 'number',\n",
       "          'title': 'Decay factor',\n",
       "          'nullable': True,\n",
       "          'description': 'Represents the factor of exponential decay and must be > 1.0. Larger values correspond to more aggressive decay.',\n",
       "          'exclusiveMinimum': 1}},\n",
       "        'description': 'Can be used to exponentially increase the likelihood of the text generation terminating once a specified number of tokens have been generated.',\n",
       "        'additionalProperties': False},\n",
       "       'max_new_tokens': {'type': 'integer',\n",
       "        'title': 'Max new tokens',\n",
       "        'default': 20,\n",
       "        'maximum': 1024,\n",
       "        'minimum': 1,\n",
       "        'nullable': True,\n",
       "        'description': 'Define the maximum number of tokens to generate.'},\n",
       "       'min_new_tokens': {'type': 'integer',\n",
       "        'title': 'Min new tokens',\n",
       "        'default': 1,\n",
       "        'minimum': 0,\n",
       "        'nullable': True,\n",
       "        'description': 'If stop sequences are given, they are ignored until minimum tokens are generated.'},\n",
       "       'stop_sequences': {'type': 'array',\n",
       "        'items': {'type': 'string', 'minLength': 1},\n",
       "        'title': 'Stop sequences',\n",
       "        'examples': ['[\" and \"]'],\n",
       "        'maxItems': 6,\n",
       "        'minItems': 1,\n",
       "        'nullable': True,\n",
       "        'description': 'Stop sequences are one or more strings which will cause the text generation to stop if/when they are produced as part of the output. Stop sequences encountered prior to the minimum number of tokens being generated will be ignored.'},\n",
       "       'decoding_method': {'type': 'string',\n",
       "        'title': 'Decoding method',\n",
       "        'default': 'sample',\n",
       "        'pattern': 'greedy|sample',\n",
       "        'nullable': True,\n",
       "        'description': 'Decoding method used for generation.'},\n",
       "       'repetition_penalty': {'type': 'number',\n",
       "        'title': 'Repetition penalty',\n",
       "        'maximum': 2,\n",
       "        'minimum': 1,\n",
       "        'nullable': True,\n",
       "        'multipleOf': 0.01,\n",
       "        'description': 'The parameter for repetition penalty. 1.00 means no penalty.'},\n",
       "       'additionalProperties': False,\n",
       "       'truncate_input_tokens': {'type': 'integer',\n",
       "        'title': 'Truncate input tokens',\n",
       "        'default': 0,\n",
       "        'minimum': 0,\n",
       "        'nullable': True,\n",
       "        'description': \"Truncate to this many input tokens. Can be used to avoid requests failing due to input being longer than configured limits. Zero means don't truncate.\"}},\n",
       "      'patternProperties': {'^(return|return_options)$': {'type': 'object',\n",
       "        'nullable': True,\n",
       "        'properties': {'input_text': {'type': 'boolean',\n",
       "          'title': 'Input text',\n",
       "          'default': False,\n",
       "          'nullable': True,\n",
       "          'description': 'Include input text'},\n",
       "         'token_ranks': {'type': 'boolean',\n",
       "          'title': 'Token ranks',\n",
       "          'default': False,\n",
       "          'nullable': True,\n",
       "          'description': 'Include rank of each returned token'},\n",
       "         'input_tokens': {'type': 'boolean',\n",
       "          'title': 'Input Tokens',\n",
       "          'default': False,\n",
       "          'nullable': True,\n",
       "          'description': 'Include list of input tokens'},\n",
       "         'top_n_tokens': {'type': 'integer',\n",
       "          'title': 'Top N tokens',\n",
       "          'maximum': 5,\n",
       "          'minimum': 0,\n",
       "          'nullable': True,\n",
       "          'description': 'Include top n candidate tokens at the position of each returned token'},\n",
       "         'token_logprobs': {'type': 'boolean',\n",
       "          'title': 'Token logprobs',\n",
       "          'default': False,\n",
       "          'nullable': True,\n",
       "          'description': 'Include logprob for each returned token'},\n",
       "         'generated_tokens': {'type': 'boolean',\n",
       "          'title': 'Generated Tokens',\n",
       "          'default': False,\n",
       "          'nullable': True,\n",
       "          'description': 'Include list of individual generated tokens'},\n",
       "         'input_parameters': {'type': 'boolean', 'nullable': True}},\n",
       "        'additionalProperties': False}},\n",
       "      'additionalProperties': False},\n",
       "     'use_default': {'type': 'boolean', 'nullable': True}},\n",
       "    'additionalProperties': False}},\n",
       "  'schema_tokenize': {'id': 2,\n",
       "   'value': {'type': 'object',\n",
       "    'required': ['model_id', 'inputs'],\n",
       "    'properties': {'inputs': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'title': 'Input strings',\n",
       "      'examples': ['[\"How are you\"]'],\n",
       "      'maxItems': 5,\n",
       "      'minItems': 1,\n",
       "      'description': 'Array of inputs'},\n",
       "     'model_id': {'type': 'string',\n",
       "      'title': 'Model ID',\n",
       "      'description': 'Model identifier'},\n",
       "     'template': {'type': 'object',\n",
       "      'oneOf': [{'required': ['id']}, {'required': ['value']}],\n",
       "      'nullable': True,\n",
       "      'required': ['data'],\n",
       "      'properties': {'id': {'type': 'string', 'nullable': False},\n",
       "       'data': {'type': 'object',\n",
       "        'nullable': False,\n",
       "        'properties': {'example_file_ids': {'type': 'array',\n",
       "          'items': {'type': 'string'},\n",
       "          'maxItems': 5,\n",
       "          'minItems': 0}},\n",
       "        'additionalProperties': True},\n",
       "       'value': {'type': 'string', 'nullable': False}},\n",
       "      'additionalProperties': False},\n",
       "     'prompt_id': {'type': 'string',\n",
       "      'title': 'Saved prompt Id',\n",
       "      'minLength': 1},\n",
       "     'parameters': {'type': 'object',\n",
       "      'nullable': True,\n",
       "      'properties': {'return_tokens': {'type': 'boolean',\n",
       "        'title': 'Return tokens',\n",
       "        'default': False,\n",
       "        'nullable': True}},\n",
       "      'additionalProperties': False},\n",
       "     'use_default': {'type': 'boolean', 'nullable': True}},\n",
       "    'additionalProperties': False}}}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = models[0][\"id\"]\n",
    "print(f\"initial model id: {model_id}\")\n",
    "\n",
    "# Some model IDs contain forward slashes which can't be directly appended to the url.\n",
    "# These slashes must first be \"escaped\" to % encoding using the ASCII character-set.\n",
    "# More escape encoding can be found here: https://www.w3schools.com/tags/ref_urlencode.ASP\n",
    "\n",
    "# change '/' in model id to '%2F'\n",
    "model_id = model_id.replace(\"/\",\"%2F\")\n",
    "print(f\"escaped model id: {model_id}\")\n",
    "\n",
    "url = WATSONX_AI_BASE_URL + \"/models/\" + model_id\n",
    "response = requests.get(url=url, headers=headers)\n",
    "model_info = response.json()\n",
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e4f10",
   "metadata": {},
   "source": [
    "### Lab Complete\n",
    "Don't forget to explore the [Watsonx.ai's REST API](https://workbench.res.ibm.com/docs/api-reference) to explore the the full list of capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c1822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
