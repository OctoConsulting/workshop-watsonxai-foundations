{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1788701",
   "metadata": {},
   "source": [
    "# Lab 3: Intro to Using IBM GenAI Python Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1bb64",
   "metadata": {},
   "source": [
    "Welcome to the Lab 3. \n",
    "\n",
    "In the previous lab, we explored the challenges of prompt engineering; learning how to tweak our wording, choose different model plus optimize model parameters. Minor changes can significantly enhance the results generated by language models.\n",
    "\n",
    "In this lab, we will apply our new knowledge to a real-world use case as we migrate from prompt engineering within the Watsonx.ai Workbench to coding prompts in Python. Using the [IBM GenAI Python library](https://ibm.github.io/ibm-generative-ai/) to programmatically interact with Watsonx.ai, we will use templates to streamline our interaction with the language model and maximize its potential.\n",
    "\n",
    "The concept of Prompt Patterns provided by IBM's GenAI Python library allows you to construct templates that can be easily filled with specific information to generate a wide range of outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755db8ef",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "**The IBM GenAI Python library is currently in Beta and will change in the future.**\n",
    "\n",
    "Also note that `ibm-generative-ai` requires `python>=3.9`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110e08a",
   "metadata": {},
   "source": [
    "## Recreating Prompt Builder Prompts Using GenAI Prompt Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d991e3a4",
   "metadata": {},
   "source": [
    "### Scenario: Personalized Recommendation for XYZ Retail Company <a id=\"step3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f1fb7",
   "metadata": {},
   "source": [
    "XYZ Retail is a popular online retail store that sells a wide range of products, including electronics, clothing, home goods, and more. They have a large customer base and want to provide a personalized shopping experience to enhance customer satisfaction and boost sales.\n",
    "\n",
    "To achieve that goal, XYZ wants to leverage generative AI to create fact sheets about each of their customers. These fact sheets will summarize relevant information such as customer demographics (name, age, location), and purchase history. These fact sheets will help XYZ Retail's sales team build stronger customer relationships, increase customer satisfaction and drive repeat purchases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d30ff",
   "metadata": {},
   "source": [
    "You start by performing prompt engineering in Prompt Lab, and you might test base model output with an initial prompt like this:\n",
    "\n",
    "![title](../images/prompt_with_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a7da9",
   "metadata": {},
   "source": [
    "The model's recommendation is not accurate or useful as the customer Michael Jones had bought toys and games not outdoor activewear. Fortunately you learned in the Prompt Engineering lab that Few Shot Learning can help you obtain better results. \n",
    "\n",
    "What happens when we provide a few examples using Prompt Builder to guide the LLM into generating more meaningful recommendations. \n",
    "\n",
    "![title](../images/prompt_with_example.png?token=AAC77XO2FBIVGZZYWCD7BLLEUWKPC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fad598",
   "metadata": {},
   "source": [
    "Great, the product recommendation for Michael Jones is much better.  However how do you productionize your few shot prompting to generate recommendations for all of XYZ Retail customers? Copy and pasting each customer's info into Prompt Builder would take too long.  \n",
    "\n",
    "You'll need a programmatic solution.  Maybe you could even generate a large set of examples then use that for Tuning a model in Watsonx.ai.  But we're getting ahead of ourselves as you'll learn about building a Prompt Tuning dataset in a later lab.\n",
    "\n",
    "Here is what you will learn in the following steps:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../images/scenario_flow_chart03.png?token=AAC77XKT7EJEOFXFCC5RXPTEUWKTQ\" width=\"600\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4d9fa",
   "metadata": {},
   "source": [
    "## 1. Load the required libraries  <a id=\"step1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "212e985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from genai.model import Credentials, Model\n",
    "from genai.schemas import GenerateParams, ModelType\n",
    "from genai.prompt_pattern import PromptPattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f48ad8",
   "metadata": {},
   "source": [
    "## 2. Create a Factsheet for each customer using Prompt Patterns  <a id=\"step2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd643142",
   "metadata": {},
   "source": [
    "### **2.1 What are Prompt Patterns?**\n",
    "\n",
    "The [PromptPattern class](https://ibm.github.io/ibm-generative-ai/rst_source/genai.prompt.prompt_pattern.html) in the [IBM GenAI Python library](https://ibm.github.io/ibm-generative-ai/) provides a flexible approach to creating prompts from structured templates.  We will use the PromptPattern class to simplify creation of our few shot prompts for XYZ Retail.\n",
    "\n",
    "XYZ Retail has provided you their customer's data in .csv format. To generate prompts for each customer, you will need to transform the prompt that you engineered in Prompt Builder into a more useful programmatic format. Using the Prompts Pattern class, you can easily substitute customer data from a file to generate one or multiple prompts.\n",
    "\n",
    "The PromptPattern class defines a schema where variables to replace are placed inside double curly braces \"{{}}\". These curly braces serve as a placeholder for the actual data that will be substituted into the template.\n",
    "\n",
    "Let's see how this works in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bcfa88",
   "metadata": {},
   "source": [
    "### **2.2 Creating a simple prompt from a template**\n",
    "\n",
    "A prompt pattern can be created using the PromptPattern class from a string, file, or url. There are [additional PromptPattern examples](https://ibm.github.io/ibm-generative-ai/rst_source/examples/examples.html) provided in the IBM GenAI documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc5148",
   "metadata": {},
   "source": [
    "#### 2.2.1 Prompt Pattern From String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97cee4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input: Jane Doe is 43 and lives in San Francisco, CA. They bought groceries, household goods and travel supplies"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"input: {{name}} {{family_name}} is {{age}} and lives in {{location}}. They bought {{purchase_history}}\"\n",
    "\n",
    "prompt = PromptPattern.from_str(pattern)\n",
    "prompt.sub(\"name\", \"Jane\").sub(\"family_name\", \"Doe\").sub(\"age\", \"43\").sub(\"location\", \"San Francisco, CA\").sub(\"purchase_history\", \"groceries, household goods and travel supplies\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a6cdb",
   "metadata": {},
   "source": [
    "#### 2.2.2 Prompt Pattern From File\n",
    "Prompt patterns can also be stored as a yaml file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4c511aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPLATE:\n",
      "input: \"{{name_1}} {{family_name_1}} is {{age_1}} years old and lives in {{city_1}}, {{state_1}}. Their purchase history includes {{purchase_history_1}}.\"\n",
      "output: \"Recommendations:\\n Item 1: {{recommendation_1_1}}\\nItem 2: {{recommendation_2_1}}\"\n",
      "input: \"{{name_2}} {{family_name_2}} is {{age_2}} years old and lives in {{city_2}}, {{state_2}}. Their purchase history includes {{purchase_history_2}}.\"\n",
      "output: \"Recommendations:\\n Item 1: {{recommendation_1_2}}\\nItem 2: {{recommendation_2_2}}\"\n",
      "input: \"{{name_3}} {{family_name_3}} is {{age_3}} years old and lives in {{city_3}}, {{state_3}}. Their purchase history includes {{purchase_history_3}}.\"\n",
      "output: \"\"\n",
      "\n",
      "\n",
      "POPULATED TEMPLATE:\n",
      "input: \"Jane Doe is 43 years old and lives in San Francisco, CA. Their purchase history includes groceries, household goods and travel supplies.\"\n",
      "output: \"Recommendations:\\n Item 1: Basket of organic fruits\\nItem 2: Lightweight carry-on suitcase\"\n",
      "input: \"Jane Doe is 43 years old and lives in San Francisco, CA. Their purchase history includes groceries, household goods and travel supplies.\"\n",
      "output: \"Recommendations:\\n Item 1: Basket of organic fruits\\nItem 2: Lightweight carry-on suitcase\"\n",
      "input: \"Jane Doe is 43 years old and lives in San Francisco, CA. Their purchase history includes groceries, household goods and travel supplies.\"\n",
      "output: \"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_path_to_file = \"../templates/customer_factsheet.yaml\"\n",
    "\n",
    "prompt = PromptPattern.from_file(_path_to_file)\n",
    "print(\"TEMPLATE:\\n\" + str(prompt))\n",
    "\n",
    "# Iterate over the numbers 1, 2 and 3 appending each to\n",
    "for x in range(1, 4):\n",
    "    prompt.sub(f\"name_{x}\", \"Jane\").sub(f\"family_name_{x}\", \"Doe\").sub(f\"age_{x}\", \"43\").sub(f\"city_{x}\", \"San Francisco\").sub(f\"state_{x}\", \"CA\")\n",
    "    prompt.sub(f\"purchase_history_{x}\", \"groceries, household goods and travel supplies\")\n",
    "    prompt.sub(f\"recommendation_1_{x}\", \"Basket of organic fruits\")\n",
    "    prompt.sub(f\"recommendation_2_{x}\", \"Lightweight carry-on suitcase\")\n",
    "print(\"\\nPOPULATED TEMPLATE:\\n\" + str(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85c4bd",
   "metadata": {},
   "source": [
    "## 3. Create Prompt Examples based on Customers Factsheet <a id=\"step3\"></a>\n",
    "The value of PromptPattern arises when generating a large number of prompts either as examples for bulk evaluation of an engineered prompt or for creation of a Tuning dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e71a4",
   "metadata": {},
   "source": [
    "### 3.1 Bulk Creation of Prompts\n",
    "We can now generate few shot Prompts from rows in a csv using \"sub_all_from_csv\". This could also be done from json.  Details can be found in the [PromptPattern class documentation](https://ibm.github.io/ibm-generative-ai/rst_source/genai.prompt.prompt_pattern.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20d7aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPLATE:\n",
      "input: \"{{name_1}} {{family_name_1}} is {{age_1}} years old and lives in {{city_1}}, {{state_1}}. Their purchase history includes {{purchase_history_1}}.\"\n",
      "output: \"Recommendations:\\n Item 1: {{recommendation_1_1}}\\nItem 2: {{recommendation_2_1}}\"\n",
      "input: \"{{name_2}} {{family_name_2}} is {{age_2}} years old and lives in {{city_2}}, {{state_2}}. Their purchase history includes {{purchase_history_2}}.\"\n",
      "output: \"Recommendations:\\n Item 1: {{recommendation_1_2}}\\nItem 2: {{recommendation_2_2}}\"\n",
      "input: \"{{name_3}} {{family_name_3}} is {{age_3}} years old and lives in {{city_3}}, {{state_3}}. Their purchase history includes {{purchase_history_3}}.\"\n",
      "output: \"\"\n",
      "\n",
      "\n",
      "POPULATED TEMPLATE:\n",
      "input: \"John Smith is 30 years old and lives in San Francisco, CA. Their purchase history includes Books electronics home_goods.\"\n",
      "output: \"Recommendations:\\n Item 1: Kindle Paperwhite - This e-reader is perfect for book lovers who want a lightweight and portable device that can hold thousands of books. It has a glare-free display and a long battery life, so you can read for hours on end without having to worry about running out of power.\\nItem 2: Google Home Mini - This smart speaker is perfect for controlling your home's smart devices with your voice. You can use it to play music, set alarms, get news, and more. It's also a great way to stay connected with friends and family.\"\n",
      "input: \"Jane Doe is 25 years old and lives in New York, NY. Their purchase history includes Clothing shoes cosmetics.\"\n",
      "output: \"Recommendations:\\n Item 1: Aritzia Wilfred Free Sweater - This soft and cozy sweater is perfect for a casual day out. It's available in a variety of colors, so you can find the perfect one to match your style.\\nItem 2: Steve Madden Pointed Toe Pumps - These stylish pumps are perfect for a night out on the town. They're comfortable and versatile, so you can wear them with a variety of outfits.\"\n",
      "input: \"Michael Jones is 40 years old and lives in Seattle, WA. Their purchase history includes Toys games sporting_goods.\"\n",
      "output: \"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_path_to_template_file = \"../templates/customer_factsheet.yaml\"\n",
    "_path_to_csv_file = \"../data/customer_factsheet.csv\"\n",
    "\n",
    "prompt = PromptPattern.from_file(_path_to_template_file)\n",
    "print(\"TEMPLATE:\\n\" + str(prompt))\n",
    "\n",
    "# We use a mapping table like below so each row in the CSV is mapped to the correct variable of the YAML template.\n",
    "# The recommendations for rows 1 and 2 are used for few shot training while every row's 3rd recommendation\n",
    "# is ignored as these are the recommendation for which we are evaluating our prompt's performance.\n",
    "mapping = {\n",
    "    \"name\": [\"name_1\", \"name_2\", \"name_3\"],\n",
    "    \"family_name\": [\"family_name_1\", \"family_name_2\", \"family_name_3\"],\n",
    "    \"age\": [\"age_1\", \"age_2\", \"age_3\"],\n",
    "    \"city\": [\"city_1\", \"city_2\", \"city_3\"],\n",
    "    \"state\": [\"state_1\", \"state_2\", \"state_3\"],\n",
    "    \"purchase_history\": [\"purchase_history_1\", \"purchase_history_2\", \"purchase_history_3\"],\n",
    "    \"recommendation_1\": [\"recommendation_1_1\", \"recommendation_1_2\", \"recommendation_1_3\"],\n",
    "    \"recommendation_2\": [\"recommendation_2_1\", \"recommendation_2_2\", \"recommendation_2_3\"]\n",
    "}\n",
    "\n",
    "list_of_prompts = prompt.sub_all_from_csv(csv_path=_path_to_csv_file,col_to_var=mapping)\n",
    "\n",
    "print(\"\\nPOPULATED TEMPLATE:\\n\" + str(list_of_prompts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00860a91",
   "metadata": {},
   "source": [
    "### 3.2 Additional Examples\n",
    "You can explore [additional examples of using the Prompt Pattern](https://ibm.github.io/ibm-generative-ai/rst_source/examples/prompts.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed11a20a",
   "metadata": {},
   "source": [
    "## 4. Executing prompts <a id=\"step4\"></a>\n",
    "We can now execute these few shot prompts to see how well our engineered prompt works across numerous examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b5ffb",
   "metadata": {},
   "source": [
    "### 4.1 Import Watsonx.ai access credentials and load model\n",
    "Make sure you copied the .env file that you created earlier into the same directory as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0ea437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_endpoint = os.getenv(\"GENAI_API\", None)\n",
    "if api_key is None or api_endpoint is None:\n",
    "    print(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\n",
    "else:\n",
    "    creds = Credentials(api_key=api_key, api_endpoint=api_endpoint)\n",
    "\n",
    "    params = GenerateParams(\n",
    "        decoding_method=\"greedy\",\n",
    "        max_new_tokens=100,\n",
    "        min_new_tokens=50,\n",
    "        stream=False,\n",
    "    )\n",
    "    model = Model(ModelType.FLAN_UL2, params=params, credentials=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053738c",
   "metadata": {},
   "source": [
    "### 4.2 Send prompts to Watsonx.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e3ee91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input: \"Michael Jones is 40 years old and lives in Seattle, WA. Their purchase history includes Toys games sporting_goods.\"\n",
      "output: Recommendations:n Item 1: X-Box One - The X-Box One is the latest gaming console from Microsoft. It has a high definition screen, and it is able to stream games from your Xbox 360 to the console. It also has an integrated Kinect sensor, which allows you to play games by simply moving your body.nItem 2: Xbox 360 - The Xbox 360 is a gaming console from Microsoft. It\n",
      "\n",
      "input: \"Ashley Brown is 20 years old and lives in Los Angeles, CA. Their purchase history includes Makeup skincare fashion.\"\n",
      "output: Recommendations:n Item 1: Makeup - MAC Ruby Woo LipsticknItem 2: Skincare - Clinique Dramatically Different MoisturizernItem 3: Fashion - MAC x Patrick Starrr CollectionnItem 4: Fashion - MAC x Gwen Stefani CollectionnItem 5: Fashion - MAC x Gigi Hadid Collection\n",
      "\n",
      "input: \"Emily Johnson is 55 years old and lives in Dallas, TX. Their purchase history includes Furniture appliances home_improvement_supplies.\"\n",
      "output: Recommendations:n Item 1: RefrigeratornItem 2: WashernItem 3: BednItem 4: CouchnItem 5: DesknItem 6: LampnItem 7: Desk ChairnItem 8: Bed FramenItem 9: Bed SheetsnItem 10: Bed PillowsnItem 11: Bed SkirtnItem 12\n"
     ]
    }
   ],
   "source": [
    "responses = model.generate_as_completed(list_of_prompts)\n",
    "for i, response in enumerate(responses):\n",
    "    lines = str(list_of_prompts[i]).strip().split(\"\\n\")\n",
    "    user_description = str(lines[4])\n",
    "    print(f\"\\n{user_description}\")\n",
    "    print(f\"output: {response.generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab967e",
   "metadata": {},
   "source": [
    "### Few shot prompt analysis\n",
    "These results are not bad.  An X-Box for a cusotmer with a history of buying toys and games.  Likewise cosmetics and furniture for the other two customers accurately reflects their purchase history.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599c479",
   "metadata": {},
   "source": [
    "## 5. Congratulations\n",
    "Congratulations on completing the lab and exploring the fascinating world of bulk creation of Few Shot Prompts using PromptPatterns! \n",
    "\n",
    "Through the practical use case of generating personalized product recommendations, you have witnessed the power of tailoring prompts to individual customer profiles. By incorporating customer-specific details and programmatically generating bulk examples, you can fine-tune the model for your specific use case, resulting in more accurate and tailored outputs. \n",
    "\n",
    "Continuously iterating and refining your prompts based on these examples will unlock the full potential of language models and enhance their performance across various domains. Keep experimenting and leveraging prompt engineering techniques to optimize your interactions with language models and drive impactful results in your projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fb8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
